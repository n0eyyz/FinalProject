import os
import json
import openai
import google.generativeai as genai
import subprocess
from youtube_transcript_api import YouTubeTranscriptApi
from pydub import AudioSegment
from dotenv import load_dotenv
from fastapi import FastAPI, Request
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
import uvicorn
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
import time
from pydantic import BaseModel
from urllib.parse import urlparse


# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
load_dotenv()

# --- 1. ì„¤ì •: í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ì™€ ìœ íŠœë¸Œ ë§í¬ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤. ---
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

# API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ì„ ê²½ìš° ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•˜ê³  ì¢…ë£Œ
if not OPENAI_API_KEY or not GOOGLE_API_KEY:
    raise ValueError("ì˜¤ë¥˜: .env íŒŒì¼ì— OPENAI_API_KEYì™€ GOOGLE_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")

# ê¶Œí•œ ì„¤ì • (ê°œë°œ ì¤‘ì—ë§Œ ì „ì²´ í—ˆìš©)
app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# API í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
openai.api_key = OPENAI_API_KEY
genai.configure(api_key=GOOGLE_API_KEY)

def get_transcript_from_youtube(video_url: str) -> str:
    """
    ìœ íŠœë¸Œ ì˜ìƒì—ì„œ í…ìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    ìë§‰ì´ ì—†ì„ ê²½ìš°, ìŒì›ì„ ë‹¤ìš´ë°›ì•„ STTë¥¼ ìˆ˜í–‰í•˜ë©°, íŒŒì¼ í¬ê¸°ê°€ 25MBë¥¼ ë„˜ìœ¼ë©´ ë¶„í• í•˜ì—¬ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    """
    try:
        video_id = video_url.split("v=")[1].split("&")[0]
        print(f"âœ… ì˜ìƒ ID '{video_id}'ì˜ ìë§‰ ì¶”ì¶œì„ ì‹œë„í•©ë‹ˆë‹¤.")
        transcript_list = YouTubeTranscriptApi.get_transcript(video_id, languages=['ko', 'en'])
        full_transcript = " ".join([item['text'] for item in transcript_list])
        print("âœ… 'youtube-transcript-api'ë¥¼ í†µí•´ ìë§‰ì„ ì„±ê³µì ìœ¼ë¡œ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")
        return full_transcript
    except Exception as e:
        print(f"âš ï¸ ìë§‰ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ ({e}). ìŒì› ì¶”ì¶œ ë° STTë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
        try:
            output_filename = "temp_audio.m4a"
            print(f"â¡ï¸ 'yt-dlp'ë¡œ ìŒì›ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤...")
            subprocess.run(
                ["yt-dlp", "-x", "--audio-format", "m4a", "-o", output_filename, video_url],
                check=True, capture_output=True
            )
            print("âœ… ìŒì› ë‹¤ìš´ë¡œë“œ ì™„ë£Œ.")

            # --- ì˜¤ë””ì˜¤ íŒŒì¼ ë¶„í•  ì²˜ë¦¬ ë¡œì§ ---
            file_size = os.path.getsize(output_filename)
            WHISPER_API_LIMIT = 25 * 1024 * 1024  # 25MB

            if file_size < WHISPER_API_LIMIT:
                print("â¡ï¸ íŒŒì¼ í¬ê¸°ê°€ ì‘ì•„ ë¶„í•  ì—†ì´ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
                with open(output_filename, "rb") as audio_file:
                    transcription = openai.audio.transcriptions.create(model="whisper-1", file=audio_file)
                full_text = transcription.text
            else:
                print(f"âš ï¸ íŒŒì¼ í¬ê¸°({file_size / 1024 / 1024:.2f}MB)ê°€ 25MBë¥¼ ì´ˆê³¼í•˜ì—¬ ë¶„í•  ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
                audio = AudioSegment.from_file(output_filename)
                # 10ë¶„(600,000ms) ë‹¨ìœ„ë¡œ ìë¥´ê¸°
                chunk_length_ms = 10 * 60 * 1000
                chunks = [audio[i:i + chunk_length_ms] for i in range(0, len(audio), chunk_length_ms)]
                
                full_text = ""
                for i, chunk in enumerate(chunks):
                    chunk_filename = f"temp_chunk_{i}.m4a"
                    print(f"â¡ï¸ {i+1}/{len(chunks)}ë²ˆì§¸ ì¡°ê° ì²˜ë¦¬ ì¤‘...")
                    chunk.export(chunk_filename, format="mp4") # m4aëŠ” mp4 ì»¨í…Œì´ë„ˆ ì‚¬ìš©
                    with open(chunk_filename, "rb") as chunk_file:
                        transcription = openai.audio.transcriptions.create(model="whisper-1", file=chunk_file)
                        full_text += transcription.text + " "
                    os.remove(chunk_filename)
            
            os.remove(output_filename) # ì›ë³¸ ì˜¤ë””ì˜¤ íŒŒì¼ ì‚­ì œ
            print("âœ… Whisper STT ë³€í™˜ ì™„ë£Œ.")
            return full_text

        except subprocess.CalledProcessError as e_dlp:
            print(f"âŒ yt-dlp ìŒì› ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e_dlp.stderr.decode()}")
            return None
        except Exception as e_whisper:
            print(f"âŒ Whisper ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e_whisper}")
            return None
        
def extract_locations_with_gemini(transcript: str) -> list:
    """
    Gemini APIë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ì—ì„œ ì¥ì†Œ ì´ë¦„ê³¼ ì¢Œí‘œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    if not transcript:
        print("âš ï¸ ì²˜ë¦¬í•  í…ìŠ¤íŠ¸ê°€ ì—†ì–´ ì¥ì†Œ ì¶”ì¶œì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return []

    print("â¡ï¸ Gemini APIë¡œ ì¥ì†Œ ë° ì¢Œí‘œ ì¶”ì¶œì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    model = genai.GenerativeModel('gemini-1.5-pro')
    
    # --- ì—¬ê¸°ë¶€í„°ê°€ ê°œì„ ëœ ì˜ë¬¸ í”„ë¡¬í”„íŠ¸ì…ë‹ˆë‹¤ ---
    prompt = f"""
    You are an expert AI specializing in analyzing YouTube food vlogs to extract restaurant and cafe names.
    Your task is to identify all the specific names of places like restaurants, cafes, bakeries, and food stalls that the vlogger visits or mentions in the provided script.

    **Instructions:**
    1.  Focus only on specific, proper names of establishments (e.g., "Fengmi Bunsik", "Cafe Waileddeog").
    2.  Exclude general locations like "Yaksu-dong" or "near Yaksu Station" unless they are part of a specific store name. Do not extract addresses.
    3.  Exclude names of people or general items. For example, if the text says "I met Cheolsu at the market", do not extract "Cheolsu".
    4.  Return the results as a JSON array of objects. Each object must contain "name", "lat", and "lng" keys.
    5.  If you cannot find the precise coordinates for a place on Google Maps, exclude it from the list.
    6.  The final output must be only the JSON array, with no other text or explanations.

    **Example:**
    Text: "First, I went to Gold PÃ¢tisserie for some bread, then had lunch at a place called Daehan Gukbap. It was great."
    Correct Output:
    [
        {{"name": "Gold PÃ¢tisserie", "lat": 37.5, "lng": 127.0}},
        {{"name": "Daehan Gukbap", "lat": 37.5, "lng": 127.0}}
    ]

    **Now, analyze the following text:**
    ---
    Text: "{transcript}"
    ---
    JSON Result:
    """
    # --- í”„ë¡¬í”„íŠ¸ëŠ” ì—¬ê¸°ê¹Œì§€ì…ë‹ˆë‹¤ ---
    
    response = None
    try:
        response = model.generate_content(prompt)
        result_text = response.text.strip().lstrip('```json').rstrip('```')
        locations = json.loads(result_text)
        print("âœ… Gemini ì¥ì†Œ ì¶”ì¶œ ì™„ë£Œ.")
        return locations
    except Exception as e:
        print(f"âŒ Gemini API ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        if response:
            print(f"ë°›ì€ ì‘ë‹µ: {response.text}")
        return []

def extract_instagram_text(post_url: str) -> str:
    chrome_options = Options()
    # chrome_options.add_argument("--headless")  # í…ŒìŠ¤íŠ¸ ì‹œ êº¼ë‘ê¸°
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--lang=ko_KR")
    chrome_options.add_argument("user-agent=Mozilla/5.0 ...")
    
    driver = webdriver.Chrome(options=chrome_options)
    try:
        print(f"[STEP 1] URL ì ‘ê·¼: {post_url}")
        driver.get(post_url)
        time.sleep(2)
        
        # ë¡œê·¸ì¸ íŒì—… ë‹«ê¸°
        try:
            close_btn = WebDriverWait(driver, 5).until(
                EC.element_to_be_clickable((By.XPATH, "//div[@role='button' and @aria-label='ë‹«ê¸°']"))
            )
            driver.execute_script("arguments[0].click();", close_btn)
            print("[STEP 2] íŒì—… ë‹«ê¸° ì„±ê³µ")
        except Exception as e:
            print("[STEP 2] íŒì—… ë‹«ê¸° ì—†ìŒ/ì‹¤íŒ¨", e)
        
        # 'ë” ë³´ê¸°' í´ë¦­
        try:
            more_btn = WebDriverWait(driver, 3).until(
                EC.element_to_be_clickable((By.XPATH, "//span[text()='ë” ë³´ê¸°']"))
            )
            more_btn.click()
            print("[STEP 3] 'ë” ë³´ê¸°' í´ë¦­ ì„±ê³µ")
            time.sleep(1)
        except Exception as e:
            print("[STEP 3] 'ë” ë³´ê¸°' ë²„íŠ¼ ì—†ìŒ/ì‹¤íŒ¨", e)
        
        # main/h1/div/spanì—ì„œ ì¶”ì¶œ
        try:
            main = driver.find_element(By.TAG_NAME, "main")
            print("[STEP 4] main ì°¾ìŒ")
            try:
                h1 = main.find_element(By.TAG_NAME, "h1")
                print(f"[STEP 5] h1ì—ì„œ ë³¸ë¬¸ ì¶”ì¶œ: {h1.text[:100]}")
                return h1.text.strip()
            except Exception as e:
                print("[STEP 5] h1 ë³¸ë¬¸ ì—†ìŒ", e)
        except Exception as e:
            print("[STEP 4] main ì—†ìŒ", e)
        
        # Fallback: meta íƒœê·¸ì—ì„œ ë³¸ë¬¸ ì¶”ì¶œ
        metas = driver.find_elements(By.TAG_NAME, "meta")
        for m in metas:
            name = m.get_attribute("name") or m.get_attribute("property")
            if name in ["og:description", "description"]:
                content = m.get_attribute("content")
                if content and len(content) > 10:
                    print(f"[STEP 6] meta {name}ì—ì„œ ë³¸ë¬¸ ì¶”ì¶œ: {content[:100]}")
                    return content.strip()
        
        print("[STEP 7] ë³¸ë¬¸ ì¶”ì¶œ ì‹¤íŒ¨ (main/h1/meta ëª¨ë‘ ì—†ìŒ)")
        return "(ë³¸ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤)"
    finally:
        driver.quit()

# ë””ë²„ê¹… ì „ìš© (ì‹¤íŒ¨ ì‹œ ë¡œê·¸ ì €ì¥)
def _save_debug_page(driver, filename):
    try:
        with open(filename, "w", encoding="utf-8") as f:
            f.write(driver.page_source)
        print(f"ğŸ” ë””ë²„ê¹…ìš© í˜ì´ì§€ ì†ŒìŠ¤ë¥¼ {filename}ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
    except Exception:
        pass


# ì¸ìŠ¤íƒ€ ë§í¬ê°€ ì˜ˆì™¸ì ìœ¼ë¡œ ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°ê°€ ë¶™ì€ ì±„ ì „ì†¡ë˜ëŠ” ê²½ìš°
# def clean_instagram_url(url):
#     parsed = urlparse(url)
#     return f"{parsed.scheme}://{parsed.netloc}{parsed.path}"
# -> ì´í›„ ì—”ë“œí¬ì¸íŠ¸ì—ì„œ
# insta_url = clean_instagram_url(insta_url) ì¶”ê°€í•´ì£¼ì„¸ìš”.


@app.post("/extract-ylocations")
async def extract_ylocations(request: Request):
    """
    í”„ë¡ íŠ¸ì—ì„œ { "youtube_url": "..." } í˜•íƒœë¡œ ìš”ì²­ì„ ë³´ë‚´ë©´
    ì¥ì†Œëª…/ìœ„ë„/ê²½ë„ jsonì„ ë¦¬í„´
    """
    data = await request.json()
    youtube_url = data.get("youtube_url")
    if not youtube_url:
        return JSONResponse({"error": "youtube_url í•„ìˆ˜"}, status_code=400)
    
    # ìŠ¤í¬ë¦½íŠ¸ ì¶”ì¶œ
    script = get_transcript_from_youtube(youtube_url)
    if not script:
        return JSONResponse({"error": "ìœ íŠœë¸Œì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨"}, status_code=500)
    
    # ì¥ì†Œ ì¶”ì¶œ
    locations = extract_locations_with_gemini(script)
    if not locations:
        return JSONResponse({"error": "ì¥ì†Œ ì¶”ì¶œ ì‹¤íŒ¨"}, status_code=500)
    
    # ìµœì¢… json ì‘ë‹µ
    return JSONResponse(locations)


@app.post("/extract-ilocations")
async def extract_ilocations(request : Request):
    data = await request.json()
    insta_url = data.get("insta_url")
    if not insta_url or "instagram.com/p/" not in insta_url:
        return JSONResponse(status_code=400, content={"error": "ìœ íš¨í•œ ì¸ìŠ¤íƒ€ê·¸ë¨ ê²Œì‹œë¬¼ URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”."})
    
    text = extract_instagram_text(insta_url)
    if not text:
        return JSONResponse({"error": "ì¸ìŠ¤íƒ€ê·¸ë¨ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."}, status_code=500)
    locations = extract_locations_with_gemini(text)
    if not locations:
        return JSONResponse({"error": "ì¥ì†Œ ì¶”ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."}, status_code=500)
    
    return JSONResponse({"insta_url": insta_url, "locations": locations}, status_code=500)

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=9000)

